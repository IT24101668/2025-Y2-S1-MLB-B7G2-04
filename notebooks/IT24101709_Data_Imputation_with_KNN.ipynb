{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNhjj5lv7tDK",
        "outputId": "bbb5e847-0ef4-472f-85dc-6a0df1c9e42b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json file created successfully.\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.8.3)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.3)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
            "Dataset URL: https://www.kaggle.com/datasets/wasiqaliyasir/breast-cancer-dataset\n",
            "License(s): apache-2.0\n",
            "Downloading breast-cancer-dataset.zip to /content/data\n",
            "  0% 0.00/48.7k [00:00<?, ?B/s]\n",
            "100% 48.7k/48.7k [00:00<00:00, 169MB/s]\n",
            "Dataset downloaded and unzipped successfully.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Data to write\n",
        "kaggle_credentials = {\n",
        "    \"username\": \"harikaran123r\",\n",
        "    \"key\": \"0e4de6becd2e7a91773fd195c8878f3a\"\n",
        "}\n",
        "\n",
        "# Write to kaggle.json\n",
        "with open(\"kaggle.json\", \"w\") as json_file:\n",
        "    json.dump(kaggle_credentials, json_file, indent=4)\n",
        "\n",
        "print(\"kaggle.json file created successfully.\")\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Create the kaggle directory\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "\n",
        "# Move kaggle.json into the directory\n",
        "!mv kaggle.json /root/.kaggle/\n",
        "\n",
        "# Set permissions\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "# Download and unzip the dataset\n",
        "!pip install kaggle\n",
        "!kaggle datasets download -d wasiqaliyasir/breast-cancer-dataset -p /content/data --unzip\n",
        "print(\"Dataset downloaded and unzipped successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "# Load CSV (assuming processed by previous steps)\n",
        "data_dir = \"/content/data\"\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "labels_df = pd.read_csv(f\"{data_dir}/Breast_cancer_dataset.csv\").dropna().reset_index(drop=True)\n",
        "print(f\"Original CSV entries: {len(labels_df)}\")\n",
        "if len(labels_df) == 0:\n",
        "    print(\"Warning: Dataset is empty. Please verify the file or download.\")\n",
        "    exit()\n",
        "\n",
        "# Technique: Impute missing values using KNN (K-Nearest Neighbors) imputation.\n",
        "# Justification: While this dataset has no missing values, KNN imputation can estimate missing feature values (e.g., 'radius_mean') based on similar samples, making the pipeline robust for future datasets with incomplete tumor measurements, enhancing cancer diagnosis reliability.\n",
        "# Implementation\n",
        "# Create a copy to simulate potential missing data (for demonstration)\n",
        "labels_df_impute = labels_df.copy()\n",
        "if len(labels_df_impute) == 0:\n",
        "    print(\"Warning: No data to impute. Skipping imputation step.\")\n",
        "else:\n",
        "    # Simulate missing values (e.g., 5% of 'radius_mean' set to NaN)\n",
        "    np.random.seed(42)\n",
        "    mask = np.random.random(labels_df_impute['radius_mean'].shape) < 0.05\n",
        "    labels_df_impute.loc[mask, 'radius_mean'] = np.nan\n",
        "    print(f\"Number of simulated missing values in 'radius_mean': {labels_df_impute['radius_mean'].isnull().sum()}\")\n",
        "\n",
        "    # Apply KNN imputation\n",
        "    imputer = KNNImputer(n_neighbors=5)\n",
        "    features = labels_df_impute.drop(['id', 'diagnosis'], axis=1).columns\n",
        "    labels_df_impute[features] = imputer.fit_transform(labels_df_impute[features])\n",
        "    print(f\"Missing values after imputation: {labels_df_impute['radius_mean'].isnull().sum()}\")\n",
        "\n",
        "    # EDA Visualization: Histogram of 'radius_mean' before and after imputation\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.hist(labels_df['radius_mean'], bins=20, alpha=0.7, label='Original')\n",
        "    plt.hist(labels_df_impute.loc[mask, 'radius_mean'], bins=20, alpha=0.5, label='Missing (Before)', color='red')\n",
        "    plt.title('Radius Mean Before Imputation')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(labels_df_impute['radius_mean'], bins=20, alpha=0.7, label='Imputed')\n",
        "    plt.title('Radius Mean After Imputation')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    print('Interpretation: Imputation smoothly integrates missing values into the distribution, maintaining data integrity for modeling.')"
      ],
      "metadata": {
        "id": "vjuP-7awFOTA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b905df0f-d120-4129-9b87-511487a282cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original CSV entries: 0\n",
            "Warning: Dataset is empty. Please verify the file or download.\n",
            "Warning: No data to impute. Skipping imputation step.\n"
          ]
        }
      ]
    }
  ]
}